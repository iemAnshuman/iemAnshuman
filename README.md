<h1 align="center">Hi, I'm Anshuman Agrawal ğŸ‘‹</h1>

<p align="center">
  <b>HPC & Deep Learning Systems Researcher</b><br>
  <i>Optimizing the "plumbing" of AI â€” from kernels to clusters.</i>
</p>

---

### ğŸš€ Current Focus
I research **low-level optimization** for Deep Learning workloads, focusing on bridging the gap between high-level PyTorch APIs and hardware reality. My work involves:
* âš¡ **Kernel Optimization:** Writing custom **OpenAI Triton** kernels to beat eager execution (Fused Attention, Softmax).
* ğŸ“‰ **Quantization:** Implementing **4-bit/INT8** inference pipelines (AWQ/GPTQ) for deploying 7B+ models on consumer GPUs.
* ğŸŒ **Distributed Systems:** Analyzing **NCCL** communication primitives and distributed training bottlenecks (DDP/FSDP).

### ğŸ›  Tech Stack

| Domain | Tools & Frameworks |
| :--- | :--- |
| **HPC & Kernels** | `OpenAI Triton` Â· `CUDA (Concepts)` Â· `NVIDIA Nsight Compute` Â· `TensorRT` |
| **Deep Learning** | `PyTorch` Â· `HuggingFace (Transformers/PEFT)` Â· `AutoGPTQ` Â· `ONNX Runtime` |
| **Infrastructure** | `Docker` Â· `Linux (Kernel/eBPF)` Â· `Bash` Â· `Slurm` |
| **Core** | `Python (AsyncIO)` Â· `C++` Â· `PostgreSQL` Â· `NumPy` |

### ğŸ”¬ Active Experiments
* **[high-performance-deep-learning](https://github.com/iemAnshuman/high-performance-deep-learning)**: My primary research repo containing custom Triton kernels, quantization benchmarks, and distributed system simulations.
* **[Neuro-Hedge](https://github.com/iemAnshuman/neuro-hedge-sim)**: A vectorized Monte Carlo simulation engine for Reinforcement Learning.

---

<p align="center">
  <a href="mailto:asquare567@gmail.com">Email</a> â€¢ <a href="https://asquare.blog">Research Blog</a>
</p>
